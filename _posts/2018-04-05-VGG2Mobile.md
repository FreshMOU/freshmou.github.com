---
layout: post
title: TextBoxe++的VGGnet用Mobilenet替换
date: 2018-04-03
tags: 深度学习
---

现在一般的检测网络都会用VggNet来作骨架，而Vgg网络的体量有点大，不太适合嵌入式实现。Mobilenet是google提出的一个轻量网络，可以在保持较高精度的同时极大地降低网络运算量，因此Mobilenet就成了在嵌入式设备上实现深度学习的首选。

由于TextBoxes使用的是pycaffe来生成网络，所以我也基于pycaffe来生成Mobilenet的网络，对照`./python/caffe/model_libs`下的VGGNetBody来写我自己的MobileNet。因为原始的ConvBNlayer没有添加group参数，所以需要自己来添加，并且还需要添加engine参数。

Caffe中用group来实现Mobilenet的深度可分离卷积，速度比较慢，并且其CUDNN似乎不太支持，需要使用CAFFE engine。否则会报Check failed: status == CUDNN_STATUS_SUCCESS (4 vs. 0)，刚开始我以为是内存不足，但我一直将batch_size减小到1都不行，所以去网上查找资料，然后发现并解决了这个问题。

直接开始测试，报错Check failed: shape[i] >= 0 (-1 vs. 0)。

显然这是卷积到最后卷不下去了（stride！=1的情况下一般会缩小feature map）。所以我先尝试着将input_size调大，这样可以多卷几次。将input_size从384调整搭到768，可以实现训练，不过这和我们想的加速不太符合，因为输入变大，需要处理的数据也就变多了。那就只能修改网络的结构了，虽然不知道这样做好不好，但还是先改了吧，我将最后几层的pad改成1，这样可以让卷积可以卷1x1的feature map。

如果报了Out of memory的错误，那么就是需要处理的数据太多了，要么减少batch_size，要么降低输入的图片分辨率。

只用ICDAR2015的数据来训练，效果不是很好。

<br/>

![](/images/posts/2018-04-05-VGG2Mobile/1.jpg)

<br/>

### 最终结果

![](/images/posts/2018-04-05-VGG2Mobile/demo_det_result.png)

如果你的效果没有那么好，那么可以注意置信度的取值