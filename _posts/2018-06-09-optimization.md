---
layout: post
title: optimization（一）
date: 2018-06-09
tags: 性能优化
---

### 前言

&#8195;&#8195;为什么需要做性能优化？因为深度学习需要大量的计算力，而嵌入式平台不像云端服务器平台一样有超额算力，嵌入式平台需要各种抠细节来充分发挥其性能以勉强提供计算能力。现有许多框架（仍在持续更新）提供给嵌入式平台加速，如[ncnn](https://github.com/Tencent/ncnn)，[ARM Compute Library](https://github.com/ARM-software/ComputeLibrary)等。


&#8195;&#8195;一般CNN性能优化的方向有下面几种。 
- 算法层面的优化
    - 模型优化
    - 卷积计算优化
- 系统层面的优化
    - 代码冗余优化
    - 内存优化
    - 并行计算

&#8195;&#8195;算法层面的优化需要太多的数学基础，对做工程的我们来说太难了，只能等业界大佬的论文。模型的优化现在很多大佬都在做，现在主要用mobilenet，shufflenet等轻量模型做主干特征提取网络，还有用剪枝的操作来减少模型参数。  
&#8195;&#8195;卷积计算的优化主要有两种方法，
- im2col: 目前几乎所有的主流计算框架包括Caffe, MXNet等都实现了该方法。该方法把卷积变成矩阵和矩阵的乘法，然后通过各种BLAS库来计算，因为BLAS库优化的非常好，所以这个方法速度是比较快的。
- winograd: 由于乘法和加法在硬件实现上的时间复杂度一般是不一样的，乘法运算所需的时间通常远大于加法所需的时间。因此，用廉价运算代替昂贵运算也是加速运算。winograd就是通过变换来用加法来替换部分乘法以达到优化增速的目的。

&#8195;&#8195;对于工程师而言，主要是针对系统级的优化，需要考虑  
- 代码是否有冗余
- 代码是否缓存友好
- 内存重要还是速度重要
- 是否有多核可以利用
- ……

### im2col+gemm


